# ğŸ“ Curriculum Learning - 7 Ã‰tapes

## Vue d'ensemble

Le systÃ¨me d'apprentissage par curriculum a Ã©tÃ© Ã©tendu Ã  **7 Ã©tapes progressives** pour former une IA complÃ¨te et performante. Chaque Ã©tape se concentre sur une compÃ©tence spÃ©cifique tout en conservant les acquis des Ã©tapes prÃ©cÃ©dentes.

## ğŸ“‹ Les 7 Ã‰tapes

### ğŸ¯ Ã‰tape 1 : Apprendre Ã  Tirer
**Objectif** : L'IA doit apprendre Ã  tirer des projectiles de maniÃ¨re rÃ©guliÃ¨re.

**RÃ©compenses** :
- âœ… **+10.0** par projectile tirÃ© (trÃ¨s gÃ©nÃ©reux)
- âœ… **+5.0** bonus si tire vers un ennemi (dans un rayon de 45Â°)
- âœ… **+0.1** bonus de survie minimal
- âŒ **-20.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- Moyenne de **5 projectiles/Ã©pisode** sur 10 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

### ğŸ¨ Ã‰tape 2 : Apprendre Ã  Viser
**Objectif** : L'IA doit apprendre Ã  orienter ses tirs vers les ennemis.

**RÃ©compenses** :
- âœ… **+8.0** bonus proportionnel Ã  la prÃ©cision de la visÃ©e
- âœ… **+12.0** JACKPOT si tire ET vise bien (dot product > 0.3)
- âœ… **+3.0** par projectile tirÃ© (acquis de l'Ã©tape 1)
- âœ… **+20.0** par ennemi tuÃ© (preuve de bonne visÃ©e)
- âŒ **-25.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- **30% de prÃ©cision** de visÃ©e sur 10 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

### ğŸƒ Ã‰tape 3 : Apprendre Ã  se DÃ©placer
**Objectif** : L'IA doit apprendre Ã  se dÃ©placer intelligemment pour Ã©viter les ennemis.

**RÃ©compenses** :
- âœ… **+3.0** bonus pour mouvement
- âœ… **+2.0** bonus proportionnel si s'Ã©loigne des ennemis
- âœ… **+2.0** par projectile (acquis Ã©tapes 1-2)
- âœ… **+0.2** survie
- âŒ **-2.0** si trop proche des bords (< 50px)
- âŒ **-2.0** par point de dÃ©gÃ¢t reÃ§u
- âŒ **-30.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- Score de mouvement **> 0.7** sur 10 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

### ğŸ›¡ï¸ Ã‰tape 4 : Apprendre Ã  Survivre
**Objectif** : L'IA doit combiner toutes les compÃ©tences pour survivre longtemps.

**RÃ©compenses** :
- âœ… **+0.5** bonus de survie par step
- âœ… **+15.0** par ennemi tuÃ©
- âœ… **+1.0** pour mouvement (acquis Ã©tape 3)
- âœ… **+1.0** par projectile (acquis Ã©tapes 1-2)
- âœ… **+0.5** si bonne position (loin des bords)
- âŒ **-3.0** si trop proche des bords (< 100px)
- âŒ **-5.0** par point de dÃ©gÃ¢t reÃ§u
- âŒ **-100.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- Survie moyenne de **1000 steps** sur 5 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

### ğŸ’ Ã‰tape 5 : Apprendre Ã  Ramasser les Orbes d'XP
**Objectif** : L'IA doit collecter activement les orbes d'XP laissÃ©s par les ennemis.

**RÃ©compenses** :
- âœ… **+2.0** par point d'XP collectÃ© (Ã‰NORME)
- âœ… **+3.0** bonus proportionnel si se dirige vers un orbe
- âœ… **+10.0** par ennemi tuÃ© (rÃ©duit, prioritÃ© Ã  la collecte)
- âœ… **+0.5** par projectile (acquis)
- âœ… **+0.3** survie
- âŒ **-3.0** par point de dÃ©gÃ¢t reÃ§u
- âŒ **-80.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- Moyenne de **3 orbes collectÃ©s** (30 XP) par Ã©pisode sur 10 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

### ğŸƒ Ã‰tape 6 : Apprendre Ã  SÃ©lectionner les Cartes
**Objectif** : L'IA doit atteindre des level-ups pour obtenir des amÃ©liorations via les cartes.

**RÃ©compenses** :
- âœ… **+50.0** par level up atteint (MASSIF)
- âœ… **+1.5** par point d'XP collectÃ© (pour atteindre les level ups)
- âœ… **+12.0** par ennemi tuÃ©
- âœ… **+0.8** par projectile (acquis)
- âœ… **+0.4** survie
- âŒ **-4.0** par point de dÃ©gÃ¢t reÃ§u
- âŒ **-100.0** pÃ©nalitÃ© mort

**CritÃ¨res de passage** :
- Moyenne d'**1 level up** par Ã©pisode sur 5 Ã©pisodes

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

**Note** : L'IA n'a pas besoin de sÃ©lectionner manuellement les cartes (pas d'input utilisateur), mais elle apprend Ã  atteindre les niveaux pour les obtenir automatiquement.

---

### ğŸ† Ã‰tape 7 : MaÃ®trise ComplÃ¨te avec AmÃ©liorations
**Objectif** : Excellence dans tous les domaines avec optimisation des amÃ©liorations.

**RÃ©compenses** :
- âœ… **+0.6** survie par step
- âœ… **+20.0** par ennemi tuÃ©
- âœ… **+10.0** bonus par niveau au-delÃ  de 4 (exponentiel)
- âœ… **+1.0** par point d'XP collectÃ©
- âœ… **+1.5** par projectile tirÃ©
- âœ… **+1.5** pour mouvement tactique
- âœ… **+1.0** si position optimale (> 200px des bords)
- âŒ **-5.0** si trop proche des bords (< 100px)
- âŒ **-8.0** par point de dÃ©gÃ¢t reÃ§u (trÃ¨s punitif)
- âŒ **-150.0** pÃ©nalitÃ© mort (MASSIVE)

**CritÃ¨res de passage** :
- Survie moyenne de **2000 steps** sur 5 Ã©pisodes
- Moyenne de **5 kills** par Ã©pisode

**DurÃ©e d'entraÃ®nement** : 100,000 timesteps

---

## ğŸ¯ MÃ©triques d'Ã‰valuation

Pour chaque Ã©tape, l'Ã©valuation mesure :

| MÃ©trique | Description |
|----------|-------------|
| **Projectiles/Ã©pisode** | Nombre de projectiles tirÃ©s |
| **PrÃ©cision visÃ©e** | Pourcentage de tirs bien orientÃ©s vers les ennemis |
| **Score de mouvement** | IntensitÃ© et qualitÃ© du dÃ©placement |
| **Temps de survie** | Nombre de steps avant la mort |
| **Kills/Ã©pisode** | Nombre d'ennemis tuÃ©s par projectiles |
| **Orbes XP collectÃ©s** | QuantitÃ© d'XP ramassÃ©e |
| **Cartes obtenues** | Nombre de level-ups atteints |
| **Niveau moyen final** | Niveau atteint en fin d'Ã©pisode |

---

## ğŸš€ Utilisation

### Lancer le curriculum complet

```bash
cd tools/training
python curriculum_trainer.py
```

### Lancer une Ã©tape spÃ©cifique

```python
from curriculum_trainer import CurriculumLearningTrainer

trainer = CurriculumLearningTrainer()
trainer.train_stage(stage=5, total_timesteps=100000)  # Ã‰tape 5 : Orbes XP
```

### Ã‰valuer une Ã©tape

```python
trainer._evaluate_stage(stage=3)
```

---

## ğŸ“Š Progression Typique

### Ã‰tape 1 â†’ Ã‰tape 2 (Tir â†’ VisÃ©e)
L'IA passe de tirs alÃ©atoires Ã  des tirs orientÃ©s vers les ennemis.
- **Avant** : Tire dans toutes les directions
- **AprÃ¨s** : Vise majoritairement les ennemis proches

### Ã‰tape 2 â†’ Ã‰tape 3 (VisÃ©e â†’ Mouvement)
L'IA apprend Ã  se dÃ©placer tout en maintenant sa prÃ©cision de tir.
- **Avant** : Reste statique en tirant
- **AprÃ¨s** : Se dÃ©place tactiquement en tirant

### Ã‰tape 3 â†’ Ã‰tape 4 (Mouvement â†’ Survie)
L'IA optimise la combinaison mouvement + tir pour maximiser la survie.
- **Avant** : Meurt rapidement malgrÃ© le mouvement
- **AprÃ¨s** : Survit longtemps en Ã©vitant les dÃ©gÃ¢ts

### Ã‰tape 4 â†’ Ã‰tape 5 (Survie â†’ Collecte XP)
L'IA ajoute la collecte active d'XP Ã  son comportement de survie.
- **Avant** : Ignore les orbes d'XP au sol
- **AprÃ¨s** : Se dirige vers les orbes tout en survivant

### Ã‰tape 5 â†’ Ã‰tape 6 (Collecte XP â†’ Level-ups)
L'IA optimise la collecte d'XP pour atteindre rapidement les level-ups.
- **Avant** : Collecte peu d'XP, niveau bas
- **AprÃ¨s** : Collecte activement, monte en niveau

### Ã‰tape 6 â†’ Ã‰tape 7 (Level-ups â†’ MaÃ®trise)
L'IA utilise les amÃ©liorations obtenues pour exceller dans tous les domaines.
- **Avant** : Niveau 1-2 en moyenne
- **AprÃ¨s** : Niveau 5+ avec comportement expert

---

## âš™ï¸ Configuration des Timesteps

Chaque Ã©tape utilise **100,000 timesteps** par dÃ©faut, soit :
- ~1,666 Ã©pisodes de 60 steps
- ~10-15 minutes d'entraÃ®nement (selon CPU)
- **Total : 700,000 timesteps** pour le curriculum complet

### Ajustements recommandÃ©s

**EntraÃ®nement rapide (test)** :
```python
trainer.train_stage(stage, total_timesteps=50000)
```

**EntraÃ®nement standard** :
```python
trainer.train_stage(stage, total_timesteps=100000)  # Par dÃ©faut
```

**EntraÃ®nement approfondi** :
```python
trainer.train_stage(stage, total_timesteps=200000)
```

---

## ğŸ”„ Transfer Learning

Le curriculum utilise le **transfer learning** :
- Chaque Ã©tape charge le modÃ¨le de l'Ã©tape prÃ©cÃ©dente
- Les acquis sont conservÃ©s et raffinÃ©s
- L'apprentissage est cumulatif, pas isolÃ©

### Sauvegarde des modÃ¨les

| Fichier | Description |
|---------|-------------|
| `curriculum_stage_1.zip` | ModÃ¨le aprÃ¨s Ã©tape 1 (Tir) |
| `curriculum_stage_2.zip` | ModÃ¨le aprÃ¨s Ã©tape 2 (VisÃ©e) |
| `curriculum_stage_3.zip` | ModÃ¨le aprÃ¨s Ã©tape 3 (Mouvement) |
| `curriculum_stage_4.zip` | ModÃ¨le aprÃ¨s Ã©tape 4 (Survie) |
| `curriculum_stage_5.zip` | ModÃ¨le aprÃ¨s Ã©tape 5 (Collecte XP) |
| `curriculum_stage_6.zip` | ModÃ¨le aprÃ¨s Ã©tape 6 (Cartes) |
| `curriculum_stage_7.zip` | **ModÃ¨le final complet** |

---

## ğŸ® IntÃ©gration des SystÃ¨mes de Jeu

### SystÃ¨me d'Orbes XP (Ã‰tape 5)
L'environnement AI gÃ¨re automatiquement :
- CrÃ©ation d'orbes Ã  la mort des ennemis
- Attraction magnÃ©tique vers le joueur
- Collecte par collision
- Gain d'XP au systÃ¨me

### SystÃ¨me de Cartes (Ã‰tape 6-7)
Pour l'entraÃ®nement, les cartes sont **automatiquement sÃ©lectionnÃ©es** :
- L'IA n'a pas de choix manuel
- Les amÃ©liorations sont appliquÃ©es automatiquement au level-up
- Focus sur l'apprentissage de la progression plutÃ´t que du choix

**Note** : Pour un modÃ¨le complet avec choix de cartes, il faudrait Ã©tendre l'espace d'action pour inclure la sÃ©lection.

---

## ğŸ› DÃ©pannage

### L'IA ne progresse pas d'une Ã©tape
- Augmenter les timesteps d'entraÃ®nement
- VÃ©rifier que le modÃ¨le prÃ©cÃ©dent se charge correctement
- RÃ©duire les critÃ¨res de passage temporairement

### L'IA oublie les compÃ©tences prÃ©cÃ©dentes
- VÃ©rifier que les rÃ©compenses des Ã©tapes prÃ©cÃ©dentes sont conservÃ©es
- Augmenter le poids des compÃ©tences acquises dans les rÃ©compenses
- RÃ©duire le learning rate pour stabiliser l'apprentissage

### EntraÃ®nement trop lent
- Augmenter le nombre d'environnements parallÃ¨les (n_envs)
- RÃ©duire max_steps par Ã©pisode
- Utiliser CPU uniquement (plus rapide que GPU pour PPO + Pygame)

---

## ğŸ“ˆ RÃ©sultats Attendus

AprÃ¨s le curriculum complet (7 Ã©tapes), l'IA devrait Ãªtre capable de :

âœ… **Tirer rÃ©guliÃ¨rement** (15+ projectiles/Ã©pisode)  
âœ… **Viser avec prÃ©cision** (>50% de prÃ©cision)  
âœ… **Se dÃ©placer intelligemment** (Ã©vite les ennemis et les bords)  
âœ… **Survivre longtemps** (>2000 steps)  
âœ… **Collecter l'XP activement** (>50 XP/Ã©pisode)  
âœ… **Atteindre des level-ups** (Niveau 3-5+ par Ã©pisode)  
âœ… **Tuer efficacement** (>5 ennemis/Ã©pisode)  
âœ… **Optimiser sa progression** (Combine toutes les compÃ©tences)

---

## ğŸ¯ Prochaines AmÃ©liorations

### Ã‰tape 8 potentielle : StratÃ©gie de Cartes
- Espace d'action Ã©tendu pour choisir les cartes
- RÃ©compenses basÃ©es sur les synergies de cartes
- Apprentissage de builds optimaux

### Ã‰tape 9 potentielle : Multi-objectifs
- Ã‰quilibrage dynamique entre survie et kills
- Adaptation au niveau de difficultÃ©
- Comportement Ã©mergent complexe

### Optimisations
- Curriculum adaptatif (ajuste les timesteps selon la progression)
- Multi-stage parallel training (entraÃ®ner plusieurs Ã©tapes en parallÃ¨le)
- RÃ©compenses dynamiques (ajustement automatique selon les performances)

---

## ğŸ“š Ressources

- **PPO Algorithm** : [Stable Baselines3 Documentation](https://stable-baselines3.readthedocs.io/)
- **Curriculum Learning** : [OpenAI Research](https://openai.com/research/)
- **Reinforcement Learning** : [Gymnasium Documentation](https://gymnasium.farama.org/)

---

## ğŸ† Conclusion

Le systÃ¨me de curriculum learning Ã  7 Ã©tapes permet de former une IA complÃ¨te et performante de maniÃ¨re progressive et efficace. Chaque Ã©tape construit sur les prÃ©cÃ©dentes, crÃ©ant un agent capable de maÃ®triser tous les aspects du jeu.

**Temps total d'entraÃ®nement estimÃ©** : 1.5 - 2 heures  
**ModÃ¨le final** : `ai_models/curriculum_stage_7.zip`  
**Performance attendue** : Agent expert capable de survie prolongÃ©e et progression efficace
